{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b14971e9",
   "metadata": {},
   "source": [
    "# 横向联邦学习任务示例\n",
    "\n",
    "这是一个使用Delta框架编写的横向联邦学习的任务示例。\n",
    "\n",
    "数据是分布在多个节点上的[MNIST数据集](http://yann.lecun.com/exdb/mnist/)，每个节点上只有其中的一部分样本。任务是训练一个卷积神经网络的模型，进行手写数字的识别。\n",
    "\n",
    "本示例可以直接在Deltaboard中执行并查看结果。<span style=\"color:#FF8F8F;font-weight:bold\">在点击执行之前，需要修改一下个人的Deltaboard API的地址，具体请看下面第4节的说明。</span>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcef1746",
   "metadata": {},
   "source": [
    "## 1. 引入需要的包\n",
    "\n",
    "我们的计算逻辑是用torch写的。所以首先引入```numpy```和```torch```，以及一些辅助的工具，然后从```delta-task```的包中，引入Delta框架的内容，包括```DeltaNode```节点，用于调用API发送任务，以及我们本示例中要执行的横向联邦学习任务```HorizontalTask```等等："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "604d372b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, Iterable, List, Tuple, Any, Union\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from delta import DeltaNode\n",
    "from delta.task import HorizontalTask\n",
    "from delta.algorithm.horizontal import FedAvg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7741239a",
   "metadata": {},
   "source": [
    "## 2. 定义神经网络模型\n",
    "\n",
    "接下来我们来定义神经网络模型，这里和传统的神经网络模型定义完全一样："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46faaabb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class LeNet(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = torch.nn.Conv2d(1, 16, 5, padding=2)\n",
    "        self.pool1 = torch.nn.AvgPool2d(2, stride=2)\n",
    "        self.conv2 = torch.nn.Conv2d(16, 16, 5)\n",
    "        self.pool2 = torch.nn.AvgPool2d(2, stride=2)\n",
    "        self.dense1 = torch.nn.Linear(400, 100)\n",
    "        self.dense2 = torch.nn.Linear(100, 10)\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        x = self.conv1(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.pool1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.pool2(x)\n",
    "\n",
    "        x = x.view(-1, 400)\n",
    "        x = self.dense1(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.dense2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88618f57",
   "metadata": {},
   "source": [
    "## 3. 定义隐私计算任务\n",
    "\n",
    "然后可以开始定义我们的横向联邦任务了，用横向联邦学习的方式，在多节点上训练上面定义的神经网络模型\n",
    "\n",
    "在定义横向联邦学习任务时，有几部分内容是需要用户自己定义的：\n",
    "\n",
    "* ***模型训练方法***：包括损失函数、优化器，以及训练步骤的定义\n",
    "* ***数据预处理方法***：在执行训练步骤以前，对于加载的每个样本数据进行预处理的方法，具体的参数说明，可以参考[这篇文档](https://docs.deltampc.com/network-deployment/prepare-data)\n",
    "* ***模型验证方法***：在每个节点上通过验证样本集，计算模型精确度的方法\n",
    "* ***横向联邦配置***：每轮训练需要多少个节点，如何在节点上划分验证样本集合等等\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3012646",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExampleTask(HorizontalTask):\n",
    "    def __init__(self):\n",
    "        super().__init__(\n",
    "            name=\"example\", # 任务名称，用于在Deltaboard中的展示\n",
    "            dataset=\"mnist\", # 任务用到的数据集的文件名，对应于Delta Node的data文件夹下的一个文件/文件夹\n",
    "            max_rounds=2,  # 任务训练的总轮次，每聚合更新一次权重，代表一轮\n",
    "            validate_interval=1,  # 验证的轮次间隔，1表示每完成一轮，进行一次验证\n",
    "            validate_frac=0.1,  # 验证集的比例，范围(0,1)\n",
    "        )\n",
    "        \n",
    "        # 传入刚刚定义的神经网络模型\n",
    "        self.model = LeNet()\n",
    "        \n",
    "        # 模型训练时用到的损失函数\n",
    "        self.loss_func = torch.nn.CrossEntropyLoss()\n",
    "        \n",
    "        # 模型训练时的优化器\n",
    "        self.optimizer = torch.optim.SGD(\n",
    "            self.model.parameters(),\n",
    "            lr=0.1,\n",
    "            momentum=0.9,\n",
    "            weight_decay=1e-3,\n",
    "            nesterov=True,\n",
    "        )\n",
    "\n",
    "    def preprocess(self, x, y=None):\n",
    "        \"\"\"\n",
    "        数据预处理方法，会在数据加载时，对每一个样本进行预处理。\n",
    "        具体的参数说明，可以参考https://docs.deltampc.com/network-deployment/prepare-data\n",
    "        x: 原始数据集中的一个样本，类型与指定的数据集相关\n",
    "        y: 数据对应的标签，如果数据集中不包含标签，则为None\n",
    "        return: 预处理完的数据和标签（如果存在），类型需要为torch.Tensor或np.ndarray\n",
    "        \"\"\"\n",
    "        x /= 255.0\n",
    "        x *= 2\n",
    "        x -= 1\n",
    "        x = x.reshape((1, 28, 28))\n",
    "        return torch.from_numpy(x), torch.tensor(int(y), dtype=torch.long)\n",
    "\n",
    "    def train(self, dataloader: Iterable):\n",
    "        \"\"\"\n",
    "        训练步骤\n",
    "        dataloader: 训练数据集对应的dataloader\n",
    "        return: None\n",
    "        \"\"\"\n",
    "        for batch in dataloader:\n",
    "            x, y = batch\n",
    "            y_pred = self.model(x)\n",
    "            loss = self.loss_func(y_pred, y)\n",
    "            self.optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "\n",
    "    def validate(self, dataloader: Iterable) -> Dict[str, float]:\n",
    "        \"\"\"\n",
    "        验证步骤，输出验证的指标值\n",
    "        dataloader: 验证集对应的dataloader\n",
    "        return: Dict[str, float]，一个字典，键为指标的名称（str），值为对应的指标值（float）\n",
    "        \"\"\"\n",
    "        total_loss = 0\n",
    "        count = 0\n",
    "        ys = []\n",
    "        y_s = []\n",
    "        for batch in dataloader:\n",
    "            x, y = batch\n",
    "            y_pred = self.model(x)\n",
    "            loss = self.loss_func(y_pred, y)\n",
    "            total_loss += loss.item()\n",
    "            count += 1\n",
    "\n",
    "            y_ = torch.argmax(y_pred, dim=1)\n",
    "            y_s.extend(y_.tolist())\n",
    "            ys.extend(y.tolist())\n",
    "        avg_loss = total_loss / count\n",
    "        tp = len([1 for i in range(len(ys)) if ys[i] == y_s[i]])\n",
    "        precision = tp / len(ys)\n",
    "\n",
    "        return {\"loss\": avg_loss, \"precision\": precision}\n",
    "\n",
    "    def get_params(self) -> List[torch.Tensor]:\n",
    "        \"\"\"\n",
    "        需要训练的模型参数\n",
    "        在聚合更新、保存结果时，只会更新、保存get_params返回的参数\n",
    "        return: List[torch.Tensor]， 模型参数列表\n",
    "        \"\"\"\n",
    "        return list(self.model.parameters())\n",
    "\n",
    "    def algorithm(self):\n",
    "        \"\"\"\n",
    "        聚合更新算法的配置，可选算法包含在delta.algorithm.horizontal包中\n",
    "        \"\"\"\n",
    "        return FedAvg(\n",
    "            merge_interval_epoch=0,  # 聚合更新的间隔，merge_interval_epoch表示每多少个epoch聚合更新一次权重\n",
    "            merge_interval_iter=20,  # 聚合更新的间隔，merge_interval_iter表示每多少个iteration聚合更新一次，merge_interval_epoch与merge_interval_iter互斥，必须有一个为0\n",
    "            wait_timeout=20,  # 等待超时时间，用来控制一轮计算的超时时间\n",
    "            connection_timeout=20,  # 连接超时时间，用来控制流程中每个阶段的超时时间\n",
    "            min_clients=2,  # 算法所需的最少客户端数，至少为2\n",
    "            max_clients=2,  # 算法所支持的最大客户端数，必须大雨等于min_clients\n",
    "        )\n",
    "\n",
    "    def dataloader_config(\n",
    "        self,\n",
    "    ) -> Union[Dict[str, Any], Tuple[Dict[str, Any], Dict[str, Any]]]:\n",
    "        \"\"\"\n",
    "        训练集dataloader和验证集dataloader的配置，\n",
    "        每个配置为一个字典，对应pytorch中dataloader的配置\n",
    "        详情参见 https://pytorch.org/docs/stable/data.html\n",
    "        return: 一个或两个Dict[str, Any]，返回一个时，同时配置训练集和验证集的dataloader，返回两个时，分别对应训练集和验证集\n",
    "        \"\"\"\n",
    "        train_config = {\"batch_size\": 64, \"shuffle\": True, \"drop_last\": True}\n",
    "        val_config = {\"batch_size\": 64, \"shuffle\": False, \"drop_last\": False}\n",
    "        return train_config, val_config\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "600ac7be-75ef-47a8-a82c-5aedf6095f33",
   "metadata": {},
   "source": [
    "## 4. 指定执行任务用的Delta Node的API\n",
    "\n",
    "定义好了任务，我们就可以开始准备在Delta Node上执行任务了。\n",
    "\n",
    "Delta Task框架可以直接调用Delta Node API发送任务到Delta Node开始执行，只要在任务执行时指定Delta Node的API地址即可。\n",
    "\n",
    "Deltaboard提供了对于Delta Node的API的封装，为每个用户提供了一个独立的API地址，支持多人同时使用同一个Delta Node，并且能够在Deltaboard中管理自己提交的任务。\n",
    "在这里，我们使用Deltaboard提供的API来执行任务。如果用户自己搭建了Delta Node，也可以直接使用Delta Node的API。\n",
    "\n",
    "在左侧导航栏中进入“个人中心”，在Deltaboard API中，复制自己的API地址，并粘贴到下面的代码中："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1d30aac-f019-4544-81f9-0af16ea4a313",
   "metadata": {},
   "outputs": [],
   "source": [
    "DELTA_NODE_API = \"http://127.0.0.1:6704\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "133ad5fa",
   "metadata": {},
   "source": [
    "## 5. 执行隐私计算任务\n",
    "\n",
    "接下来我们可以开始运行这个模型了："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db1d1c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "task = ExampleTask()\n",
    "delta_node = DeltaNode(DELTA_NODE_API)\n",
    "delta_node.create_task(task)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9994ef7e",
   "metadata": {},
   "source": [
    "## 6. 查看执行状态\n",
    "点击执行后，可以从输出的日志看出，任务已经提交到了Delta Node的节点上。\n",
    "\n",
    "接下来，可以从左侧的导航栏中，前往“任务列表”，找到刚刚提交的任务，点击进去查看具体的执行日志了。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
